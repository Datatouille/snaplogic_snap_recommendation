{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authored by [JumpThanawut](https://github.com/orgs/Datatouille/people/JumpThanawut); Edited by [cstorm125](https://github.com/cstorm125/)\n",
    "\n",
    "Tree-based models are strong baselines when doing any type of supervised learning. They come with handy characteristics such as not requiring standardizing your features, handling categorical variables and powerful ensembling. It is always a decent thing to start with tree-based models as baselines. This notebook will get you started on training a default-parameter decision tree, random forest and gradient boosted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #uncomment if you are running from google colab\n",
    "# !wget https://github.com/Datatouille/snaplogic_snap_recommendation/archive/master.zip; unzip master\n",
    "# !mv snaplogic_snap_recommendation-master/* .\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset/train_df.csv\")\n",
    "valid_df = pd.read_csv(\"dataset/valid_df.csv\")\n",
    "submit_df = pd.read_csv(\"dataset/submit_df.csv\")\n",
    "all_df = pd.concat([train_df,valid_df,submit_df],0).reset_index(drop=True)\n",
    "train_df.shape, valid_df.shape, submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our features are discrete so we need to perform one-hot encoding before serving them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode the features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categories=[np.arange(1,5), \\\n",
    "                                np.arange(501),np.arange(501),np.arange(501),np.arange(501),\\\n",
    "                                np.arange(1,581),np.arange(1,231)])\n",
    "\n",
    "feature_cols = ['org','prev_snap_1','prev_snap_2','prev_snap_3','prev_snap_4','project','user']\n",
    "train_x = train_df[feature_cols].values\n",
    "enc_fit = enc.fit(train_x)\n",
    "train_x = enc_fit.transform(train_x)\n",
    "train_y = train_df[\"target_snap\"].values.astype(str)\n",
    "valid_x = enc_fit.transform(valid_df[feature_cols].values)\n",
    "valid_y = valid_df[\"target_snap\"].values.astype(str)\n",
    "train_x.shape, train_y.shape, valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_x, train_y)\n",
    "print(f'Accuracy: {clf.score(valid_x,valid_y)}') \n",
    "print(f'Top-5 Accuracy: {score_topk(clf,valid_x,valid_y,k=5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(train_x, train_y)\n",
    "print(f'Accuracy: {clf.score(valid_x,valid_y)}') \n",
    "print(f'Top-5 Accuracy: {score_topk(clf,valid_x,valid_y,k=5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "clf = LGBMClassifier(boosting_type='gbdt', num_leaves=31, n_estimators=10,\n",
    "                objective='ovr', num_class=486)\n",
    "clf = clf.fit(train_x, train_y)\n",
    "probs = clf.predict_proba(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {clf.score(valid_x,valid_y)}')\n",
    "print(f'Top-5 Accuracy: {score_topk(probs,valid_y,k=5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 486 target classes, it is almost impossible to diagnose how well your model performs by looking at confusion matrix like you would normally do. Using the decision tree and random forest classifier, we provide some ideas for model evaulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_tree = clf_tree.fit(train_x, train_y)\n",
    "print(f'Accuracy: {clf_tree.score(valid_x,valid_y)}') \n",
    "print(f'Top-5 Accuracy: {score_topk(clf_tree,valid_x,valid_y,k=5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest = RandomForestClassifier(n_estimators=10)\n",
    "clf_forest = clf_forest.fit(train_x, train_y)\n",
    "print(f'Accuracy: {clf_forest.score(valid_x,valid_y)}') \n",
    "print(f'Top-5 Accuracy: {score_topk(clf_forest,valid_x,valid_y,k=5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that while decision tree has higher validation accuracy, it has lower top-5 validation accuracy. In order to see how top-k number of suggestions play a part in model performance, we plot the accuracies of each model at each k. You can see that according to the top-k-vs-accuracy plot, random forest outperforms decision tree in all cases excpet when k=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accurayc curve\n",
    "accs_tree = []\n",
    "accs_forest = []\n",
    "for i in tqdm_notebook(range(1,101)):\n",
    "    accs_tree.append(score_topk(clf_tree,valid_x,valid_y,k=i))\n",
    "    accs_forest.append(score_topk(clf_forest,valid_x,valid_y,k=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zoom in on top 10\n",
    "print(f'Area Under top-k-vs-accuracy line; Tree: {sum(accs_tree)}, Forest: {sum(accs_forest)}')\n",
    "plt.plot(accs_tree)\n",
    "plt.plot(accs_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Area top-k-vs-accuracy line; Tree: {sum(accs_tree[:10])}, Forest: {sum(accs_forest[:10])}')\n",
    "plt.plot(accs_tree[:10])\n",
    "plt.plot(accs_forest[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
