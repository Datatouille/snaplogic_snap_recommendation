{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authored by [JumpThanawut](https://github.com/orgs/Datatouille/people/JumpThanawut); Edited by [cstorm125](https://github.com/cstorm125/)\n",
    "\n",
    "The `snaplogic_snap_recommendation` contains 25,331 pipelines used internally at SnapLogic. Each pipeline contains a series of **snaps**--a component with data mainpulation codes. No pipeline in this dataset belongs to SnapLogic customers.\n",
    "\n",
    "Raw data is `snaplogic_pipeline_public.json`. The resulting `snaplogic_pipeline_segment.csv` contains 147,304 rows of 5-snap segments (4 previous snaps and 1 target snap) and the following columns:\n",
    "\n",
    "* `date` - date created\n",
    "* `org` - team identifier\n",
    "* `prev_snap_1-4` - the past 1-4 snaps\n",
    "* `project` - project identifier\n",
    "* `target_snap` - snap to predict\n",
    "* `user` - user identifier\n",
    "\n",
    "The task is predict `target_snap` based on all other variables. We divide the dataset into train-validation-test splits at 70/10/20 ratio in chronological order. Performance metrics are top-1 and top-5 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #uncomment if you are running from google colab\n",
    "# !wget https://github.com/Datatouille/snaplogic_snap_recommendation/archive/master.zip; unzip master\n",
    "# !mv snaplogic_snap_recommendation-master/* .\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One pipeline consists of the following JSON format."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pipeline format\n",
    "{\n",
    "  \"date\": \"<date that the pipeline has been last updated in yyyy-MM-dd>\",\n",
    "  \"org\": <the id of organization that the pipeline belongs to>,\n",
    "  \"project\": <the id of project (subdirectory under org) that the pipeline belongs to>,\n",
    "  \"user\": <the id of user that the pipeline belongs to>,\n",
    "  \"snap_map\": {\n",
    "    \"<the id of Snap which is running number>\": <the id representing of Snap type>,\n",
    "    ...\n",
    "  },\n",
    "  \"link_map\": {\n",
    "    \"<the id of link which is running number>\": [\n",
    "      <the id of Snap which is the source of this link>,\n",
    "      <the id of Snap which is the destination of this link>\n",
    "    ],\n",
    "    ...\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: 25331\n",
      "----- First Record -----\n",
      "{\n",
      "  \"date\": \"2014-12-05\",\n",
      "  \"org\": \"4\",\n",
      "  \"project\": \"145\",\n",
      "  \"user\": \"59\",\n",
      "  \"snap_map\": {\n",
      "    \"1\": \"195\",\n",
      "    \"2\": \"240\",\n",
      "    \"3\": \"178\"\n",
      "  },\n",
      "  \"link_map\": {\n",
      "    \"1\": [\n",
      "      \"1\",\n",
      "      \"3\"\n",
      "    ],\n",
      "    \"2\": [\n",
      "      \"3\",\n",
      "      \"2\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "----- Last Record -----\n",
      "{\n",
      "  \"date\": \"2018-11-16\",\n",
      "  \"org\": \"1\",\n",
      "  \"project\": \"70\",\n",
      "  \"user\": \"114\",\n",
      "  \"snap_map\": {\n",
      "    \"1\": \"240\",\n",
      "    \"2\": \"240\",\n",
      "    \"3\": \"336\",\n",
      "    \"4\": \"167\",\n",
      "    \"5\": \"297\",\n",
      "    \"6\": \"469\",\n",
      "    \"7\": \"18\",\n",
      "    \"8\": \"240\"\n",
      "  },\n",
      "  \"link_map\": {\n",
      "    \"1\": [\n",
      "      \"1\",\n",
      "      \"4\"\n",
      "    ],\n",
      "    \"2\": [\n",
      "      \"5\",\n",
      "      \"8\"\n",
      "    ],\n",
      "    \"3\": [\n",
      "      \"2\",\n",
      "      \"3\"\n",
      "    ],\n",
      "    \"4\": [\n",
      "      \"3\",\n",
      "      \"5\"\n",
      "    ],\n",
      "    \"5\": [\n",
      "      \"8\",\n",
      "      \"1\"\n",
      "    ],\n",
      "    \"6\": [\n",
      "      \"7\",\n",
      "      \"2\"\n",
      "    ],\n",
      "    \"7\": [\n",
      "      \"4\",\n",
      "      \"6\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"snaplogic_pipeline_public.json\", \"r\") as pipeline_dataset_file:\n",
    "    pipe_list = json.load(pipeline_dataset_file)\n",
    "\n",
    "# Print dataset size.\n",
    "print(f\"Pipeline: {len(pipe_list)}\")\n",
    "\n",
    "# Print first and last record.\n",
    "print(\"----- First Record -----\")\n",
    "print(json.dumps(pipe_list[0], indent=2))\n",
    "print(\"----- Last Record -----\")\n",
    "print(json.dumps(pipe_list[-1], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some descriptive statistics about the pipelines. We found that each pipeline contains about 5.815167 snaps. Therefore, we decided to divide all pipelines into 5-snap segments for the recommendation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: 25331\n",
      "Snap: 147304\n",
      "Start Date: 2014-12-05\n",
      "Org: 4\n",
      "Project: 506\n",
      "User: 217\n",
      "Snap Type: 485\n",
      "Average Number of Snaps in a Pipeline: 5.815167\n",
      "Average Number of Links in a Pipeline: 4.671035\n"
     ]
    }
   ],
   "source": [
    "# Get some statistics of pipelines.\n",
    "date_counter = Counter()\n",
    "org_counter = Counter()\n",
    "project_counter = Counter()\n",
    "user_counter = Counter()\n",
    "snap_type_counter = Counter()\n",
    "\n",
    "for pipe in pipe_list:\n",
    "    \n",
    "    date = pipe[\"date\"]\n",
    "    org = pipe[\"org\"]\n",
    "    project = pipe[\"project\"]\n",
    "    user = pipe[\"user\"]\n",
    "    snap_map = pipe[\"snap_map\"]\n",
    "    link_map = pipe[\"link_map\"]\n",
    "    \n",
    "    date_counter[date] += 1\n",
    "    org_counter[org] += 1\n",
    "    project_counter[project] += 1\n",
    "    user_counter[user] += 1\n",
    "    \n",
    "    for snap_id in snap_map:\n",
    "        snap_type = snap_map[snap_id]\n",
    "        snap_type_counter[snap_type] += 1\n",
    "        \n",
    "num_snap = sum([len(pipe[\"snap_map\"]) for pipe in pipe_list])\n",
    "avg_num_snap_in_pipe = num_snap / len(pipe_list)\n",
    "\n",
    "num_link = sum([len(pipe[\"link_map\"]) for pipe in pipe_list])\n",
    "avg_num_link_in_pipe = num_link / len(pipe_list)\n",
    "    \n",
    "print(\"Pipeline: {:d}\".format(len(pipe_list)))\n",
    "print(\"Snap: {:d}\".format(num_snap))\n",
    "print(\"Start Date: {:s}\".format(min(date_counter.keys())))\n",
    "print(\"Org: {:d}\".format(len(org_counter)))\n",
    "print(\"Project: {:d}\".format(len(project_counter)))\n",
    "print(\"User: {:d}\".format(len(user_counter)))\n",
    "print(\"Snap Type: {:d}\".format(len(snap_type_counter)))\n",
    "print(\"Average Number of Snaps in a Pipeline: {:f}\".format(avg_num_snap_in_pipe))\n",
    "print(\"Average Number of Links in a Pipeline: {:f}\".format(avg_num_link_in_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Org -----\n",
      "{\n",
      "  \"1\": 260,\n",
      "  \"2\": 22461,\n",
      "  \"3\": 158,\n",
      "  \"4\": 2452\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Explore distribution of pipelines among orgs.\n",
    "print(\"----- Org -----\")\n",
    "print(json.dumps(org_counter, indent = 2, sort_keys = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract all the segments and save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: 147304\n"
     ]
    }
   ],
   "source": [
    "# Extract segment from pipelines.\n",
    "segment_len = 5\n",
    "segment_list = []\n",
    "\n",
    "# Represent pipeline which is DAG (directed acyclic graph) as adjacency matrix.\n",
    "def to_adj_matrix(pipe):\n",
    "    # adj_matrix = {\"<snap_id>\": [<upstream_snap>, ...], ...}\n",
    "    adj_matrix = {}\n",
    "    snap_map = pipe[\"snap_map\"]\n",
    "    link_map = pipe[\"link_map\"]\n",
    "    \n",
    "    for link_id in link_map:\n",
    "        src_id, dst_id = link_map[link_id]\n",
    "        if dst_id not in adj_matrix:\n",
    "            adj_matrix[dst_id] = []\n",
    "        if src_id not in adj_matrix[dst_id]:\n",
    "            adj_matrix[dst_id].append(src_id)\n",
    "    \n",
    "    return adj_matrix\n",
    "\n",
    "# Get segment (consecutive Snaps) from the specified Snap. The snap_id is the id of Snap which will be the last Snap in the segment.\n",
    "def get_segment(adj_matrix, snap_id, segment_len):\n",
    "    if segment_len == 1:\n",
    "        return [snap_id]\n",
    "    else:\n",
    "        upst_snap_list = adj_matrix.get(snap_id, [])\n",
    "        if len(upst_snap_list) > 0:\n",
    "            child_segment = get_segment(adj_matrix, upst_snap_list[0], segment_len-1)\n",
    "            child_segment.append(snap_id)\n",
    "            return child_segment\n",
    "        else:\n",
    "            return [snap_id]\n",
    "\n",
    "# Extract segments from pipelines.\n",
    "for pipe in pipe_list:\n",
    "    adj_matrix = to_adj_matrix(pipe)\n",
    "    snap_map = pipe[\"snap_map\"]\n",
    "    for snap_id in snap_map:\n",
    "        segment = get_segment(adj_matrix, snap_id, segment_len)\n",
    "        \n",
    "        segment_map = {\n",
    "            \"date\": pipe[\"date\"],\n",
    "            \"org\": pipe[\"org\"],\n",
    "            \"project\": pipe[\"project\"],\n",
    "            \"user\": pipe[\"user\"],\n",
    "            \"target_snap\": snap_map[snap_id]\n",
    "        }\n",
    "        \n",
    "        for i in range(1, segment_len):\n",
    "            if i < len(segment):\n",
    "                snap_type = snap_map[segment[-i-1]]\n",
    "            else:\n",
    "                snap_type = \"\"\n",
    "            segment_map[\"prev_snap_{:d}\".format(i)] = snap_type\n",
    "        \n",
    "        segment_list.append(segment_map)\n",
    "print(\"Segment: {:d}\".format(len(segment_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>org</th>\n",
       "      <th>prev_snap_1</th>\n",
       "      <th>prev_snap_2</th>\n",
       "      <th>prev_snap_3</th>\n",
       "      <th>prev_snap_4</th>\n",
       "      <th>project</th>\n",
       "      <th>target_snap</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>145</td>\n",
       "      <td>195</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>195</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>145</td>\n",
       "      <td>240</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>4</td>\n",
       "      <td>195</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>145</td>\n",
       "      <td>178</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>223</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td>414</td>\n",
       "      <td>195</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>414</td>\n",
       "      <td>223</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date org prev_snap_1 prev_snap_2 prev_snap_3 prev_snap_4 project  \\\n",
       "0  2014-12-05   4                                                     145   \n",
       "1  2014-12-05   4         178         195                             145   \n",
       "2  2014-12-05   4         195                                         145   \n",
       "3  2015-02-10   4         240         223          88                 414   \n",
       "4  2015-02-10   4          88                                         414   \n",
       "\n",
       "  target_snap user  \n",
       "0         195   59  \n",
       "1         240   59  \n",
       "2         178   59  \n",
       "3         195   59  \n",
       "4         223   59  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the dataset as table.\n",
    "df = pd.DataFrame(segment_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to file in JSON format.\n",
    "with open(\"snaplogic_pipeline_segment.json\", \"w\") as segment_file:\n",
    "    json.dump(segment_list, segment_file)\n",
    "\n",
    "#impute 0\n",
    "df[df==''] = 0\n",
    "\n",
    "# Save dataset to file in CSV format.\n",
    "df.to_csv(\"snaplogic_pipeline_segment.csv\", index=False, encoding=\"utf-8\",\n",
    "          columns=[\"date\",\"org\",\"project\", \"user\", \n",
    "                \"prev_snap_4\", \"prev_snap_3\", \"prev_snap_2\", \"prev_snap_1\", \"target_snap\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Valid-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103112, 9), (14731, 9), (29461, 9))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ends = int(df.shape[0] * 0.7)\n",
    "valid_ends = int(df.shape[0] * 0.8)\n",
    "\n",
    "train_df = df.iloc[:train_ends,:]\n",
    "valid_df = df.iloc[train_ends:valid_ends,:]\n",
    "test_df = df.iloc[valid_ends:,:]\n",
    "\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv',index=False)\n",
    "valid_df.to_csv('valid_df.csv',index=False)\n",
    "test_df.to_csv('test_df.csv',index=False)\n",
    "submit_df = test_df.copy()\n",
    "submit_df['target_snap'] = 'test'\n",
    "submit_df.to_csv('submit_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
