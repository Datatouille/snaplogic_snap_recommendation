{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authored by [JumpThanawut](https://github.com/orgs/Datatouille/people/JumpThanawut); Edited by [cstorm125](https://github.com/cstorm125/)\n",
    "\n",
    "The `snaplogic_snap_recommendation` training set contains 25,422 pipelines used internally at SnapLogic, those pipelines were built before Jan 1, 2019. The test set contains 7,614 pipelines which have been built in 2019. Each pipeline contains a series of **snaps**--a component with data mainpulation codes. No pipeline in this dataset belongs to SnapLogic customers.\n",
    "\n",
    "Raw data is `snaplogic_pipeline_public.json`. The resulting `snaplogic_pipeline_segment.csv` contains 147,304 rows of 5-snap segments (4 previous snaps and 1 target snap) and the following columns:\n",
    "\n",
    "* `date` - date created\n",
    "* `org` - team identifier\n",
    "* `prev_snap_1-4` - the past 1-4 snaps\n",
    "* `project` - project identifier\n",
    "* `target_snap` - snap to predict\n",
    "* `user` - user identifier\n",
    "\n",
    "The task is predict `target_snap` based on all other variables. We divide the dataset into train-validation-test splits at 70/10/20 ratio in chronological order. Performance metrics are top-1 and top-5 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #uncomment if you are running from google colab\n",
    "# !wget https://github.com/Datatouille/snaplogic_snap_recommendation/archive/master.zip; unzip master\n",
    "# !mv snaplogic_snap_recommendation-master/* .\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One pipeline consists of the following JSON format."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pipeline format\n",
    "{\n",
    "  \"date\": \"<date that the pipeline has been last updated in yyyy-MM-dd>\",\n",
    "  \"org\": <the id of organization that the pipeline belongs to>,\n",
    "  \"project\": <the id of project (subdirectory under org) that the pipeline belongs to>,\n",
    "  \"user\": <the id of user that the pipeline belongs to>,\n",
    "  \"snap_map\": {\n",
    "    \"<the id of Snap which is running number>\": <the id representing of Snap type>,\n",
    "    ...\n",
    "  },\n",
    "  \"link_map\": {\n",
    "    \"<the id of link which is running number>\": [\n",
    "      <the id of Snap which is the source of this link>,\n",
    "      <the id of Snap which is the destination of this link>\n",
    "    ],\n",
    "    ...\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/snaplogic_pipeline_public_test.json\", \"r\") as pipeline_dataset_file:\n",
    "    pipe_list = json.load(pipeline_dataset_file)\n",
    "\n",
    "# Print dataset size.\n",
    "print(f\"Pipeline: {len(pipe_list)}\")\n",
    "\n",
    "# Print first and last record.\n",
    "print(\"----- First Record -----\")\n",
    "print(json.dumps(pipe_list[0], indent=2))\n",
    "print(\"----- Last Record -----\")\n",
    "print(json.dumps(pipe_list[-1], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some descriptive statistics about the pipelines. We found that each pipeline contains about 5.818464 Snaps. Therefore, we decided to divide all pipelines into 5-snap segments for the recommendation dataset. Note that the real average number of Snaps per pipeline is about 12 based on the full dataset including our customers' pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get some statistics of pipelines.\n",
    "date_counter = Counter()\n",
    "org_counter = Counter()\n",
    "project_counter = Counter()\n",
    "user_counter = Counter()\n",
    "snap_type_counter = Counter()\n",
    "\n",
    "for pipe in pipe_list:\n",
    "    \n",
    "    date = pipe[\"date\"]\n",
    "    org = pipe[\"org\"]\n",
    "    project = pipe[\"project\"]\n",
    "    user = pipe[\"user\"]\n",
    "    snap_map = pipe[\"snap_map\"]\n",
    "    link_map = pipe[\"link_map\"]\n",
    "    \n",
    "    date_counter[date] += 1\n",
    "    org_counter[org] += 1\n",
    "    project_counter[project] += 1\n",
    "    user_counter[user] += 1\n",
    "    \n",
    "    for snap_id in snap_map:\n",
    "        snap_type = snap_map[snap_id]\n",
    "        snap_type_counter[snap_type] += 1\n",
    "        \n",
    "num_snap = sum([len(pipe[\"snap_map\"]) for pipe in pipe_list])\n",
    "avg_num_snap_in_pipe = num_snap / len(pipe_list)\n",
    "sd_num_snap = np.std(np.array([len(pipe[\"snap_map\"]) for pipe in pipe_list]))\n",
    "\n",
    "num_link = sum([len(pipe[\"link_map\"]) for pipe in pipe_list])\n",
    "avg_num_link_in_pipe = num_link / len(pipe_list)\n",
    "sd_num_link_in_pipe = np.std(np.array([len(pipe[\"link_map\"]) for pipe in pipe_list]))\n",
    "\n",
    "print(\"Pipeline: {:d}\".format(len(pipe_list)))\n",
    "print(\"Snap: {:d}\".format(num_snap))\n",
    "print(\"Start Date: {:s}\".format(min(date_counter.keys())))\n",
    "print(\"Org: {:d}\".format(len(org_counter)))\n",
    "print(\"Project: {:d}\".format(len(project_counter)))\n",
    "print(\"User: {:d}\".format(len(user_counter)))\n",
    "print(\"Snap Type: {:d}\".format(len(snap_type_counter)))\n",
    "print(\"Average Number of Snaps in a Pipeline: {:f}\".format(avg_num_snap_in_pipe))\n",
    "print(\"SD Number of Snaps in a Pipeline: {:f}\".format(sd_num_snap))\n",
    "print(\"Average Number of Links in a Pipeline: {:f}\".format(avg_num_link_in_pipe))\n",
    "print(\"SD Number of Links in a Pipeline: {:f}\".format(sd_num_link_in_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore distribution of pipelines among orgs. SnapLogic has 4 internal orgs on production.\n",
    "print(\"----- Org -----\")\n",
    "print(json.dumps(org_counter, indent = 2, sort_keys = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract all the segments and save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract segment from pipelines.\n",
    "segment_len = 5\n",
    "segment_list = []\n",
    "\n",
    "# Represent pipeline which is DAG (directed acyclic graph) as adjacency matrix.\n",
    "def to_adj_matrix(pipe):\n",
    "    # adj_matrix = {\"<snap_id>\": [<upstream_snap>, ...], ...}\n",
    "    adj_matrix = {}\n",
    "    snap_map = pipe[\"snap_map\"]\n",
    "    link_map = pipe[\"link_map\"]\n",
    "    \n",
    "    for link_id in link_map:\n",
    "        src_id, dst_id = link_map[link_id]\n",
    "        if dst_id not in adj_matrix:\n",
    "            adj_matrix[dst_id] = []\n",
    "        if src_id not in adj_matrix[dst_id]:\n",
    "            adj_matrix[dst_id].append(src_id)\n",
    "    \n",
    "    return adj_matrix\n",
    "\n",
    "# Get segment (consecutive Snaps) from the specified Snap. The snap_id is the id of Snap which will be the last Snap in the segment.\n",
    "def get_segment(adj_matrix, snap_id, segment_len):\n",
    "    if segment_len == 1:\n",
    "        return [snap_id]\n",
    "    else:\n",
    "        upst_snap_list = adj_matrix.get(snap_id, [])\n",
    "        if len(upst_snap_list) > 0:\n",
    "            child_segment = get_segment(adj_matrix, upst_snap_list[0], segment_len-1)\n",
    "            child_segment.append(snap_id)\n",
    "            return child_segment\n",
    "        else:\n",
    "            return [snap_id]\n",
    "\n",
    "# Extract segments from pipelines.\n",
    "for pipe in pipe_list:\n",
    "    adj_matrix = to_adj_matrix(pipe)\n",
    "    snap_map = pipe[\"snap_map\"]\n",
    "    for snap_id in snap_map:\n",
    "        segment = get_segment(adj_matrix, snap_id, segment_len)\n",
    "        \n",
    "        segment_map = {\n",
    "            \"date\": pipe[\"date\"],\n",
    "            \"org\": pipe[\"org\"],\n",
    "            \"project\": pipe[\"project\"],\n",
    "            \"user\": pipe[\"user\"],\n",
    "            \"target_snap\": snap_map[snap_id]\n",
    "        }\n",
    "        \n",
    "        for i in range(1, segment_len):\n",
    "            if i < len(segment):\n",
    "                snap_type = snap_map[segment[-i-1]]\n",
    "            else:\n",
    "                snap_type = \"\"\n",
    "            segment_map[\"prev_snap_{:d}\".format(i)] = snap_type\n",
    "        \n",
    "        segment_list.append(segment_map)\n",
    "print(\"Segment: {:d}\".format(len(segment_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset as table.\n",
    "df = pd.DataFrame(segment_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to file in JSON format.\n",
    "with open(\"dataset/snaplogic_pipeline_segment_test.json\", \"w\") as segment_file:\n",
    "    json.dump(segment_list, segment_file)\n",
    "\n",
    "#impute 0\n",
    "df[df==''] = 0\n",
    "\n",
    "# Save dataset to file in CSV format.\n",
    "df.to_csv(\"dataset/snaplogic_pipeline_segment_test.csv\", index=False, encoding=\"utf-8\",\n",
    "          columns=[\"date\",\"org\",\"project\", \"user\", \n",
    "                \"prev_snap_4\", \"prev_snap_3\", \"prev_snap_2\", \"prev_snap_1\", \"target_snap\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Valid-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"date\"], axis=1).sample(frac=1)\n",
    "df.to_csv('dataset/competition_test_df.csv',index=False)\n",
    "submit_df = df.copy()\n",
    "submit_df['target_snap'] = 'test'\n",
    "submit_df.to_csv('dataset/competition_submit_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
